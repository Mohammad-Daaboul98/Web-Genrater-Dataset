{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SHqig9seHA9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKj9svjzP995"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import json\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCGsM0CmxhKn"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    '\\n': 0,\n",
        "    '<START>': 1,\n",
        "    '<END>': 2,\n",
        "    '}': 3,\n",
        "    '{': 4,\n",
        "    ',': 5,\n",
        "    ' ': 6,\n",
        "    'header': 7,\n",
        "    'navbar-dark': 8,\n",
        "    'navbar-light': 9,\n",
        "    'navbar-primary': 10,\n",
        "    'navbar-warning': 11,\n",
        "    'navbar-danger': 12,\n",
        "    'navbar-secondary': 13,\n",
        "    'navbar-success': 14,\n",
        "    'navbar-brand': 15,\n",
        "    'navbar-toggler': 16,\n",
        "    'navbar-toggler-icon': 17,\n",
        "    'navbar-collapse': 18,\n",
        "    'navbar-nav': 19,\n",
        "    'nav-item': 20,\n",
        "    'nav-item-active': 21,\n",
        "    'nav-item-unactive': 22,\n",
        "    'nav-link': 23,\n",
        "    'nav-link-undisabled': 24,\n",
        "    'nav-link-disabled': 25,\n",
        "    'nav-link-active': 26,\n",
        "    'form-inline-success': 27,\n",
        "    'form-inline-danger': 28,\n",
        "    'form-inline-primary': 29,\n",
        "    'form-primary': 30,\n",
        "    'form-danger': 31,\n",
        "    'form-inline-secondary': 32,\n",
        "    'form-secondary': 33,\n",
        "    'form-inline-warning': 34,\n",
        "    'form-inline-dark': 35,\n",
        "    'form-dark': 36,\n",
        "    'form-inline-light': 37,\n",
        "    'from-d-flex': 38,\n",
        "    'form-control-me-2': 39,\n",
        "    'container-fluid': 40,\n",
        "    'container': 41,\n",
        "    'container-marketing': 42,\n",
        "    'main': 43,\n",
        "    'main-container': 44,\n",
        "    'carousel-slide': 45,\n",
        "    'row': 46,\n",
        "    'col': 47,\n",
        "    'col-auto': 48,\n",
        "    'col-auto-my-1': 49,\n",
        "    'col-7': 50,\n",
        "    'col-11': 51,\n",
        "    'col-12': 52,\n",
        "    'col-lg-4': 53,\n",
        "    'col-md-7': 54,\n",
        "    'col-md-5': 55,\n",
        "    'order-md-2': 56,\n",
        "    'svg-140px': 57,\n",
        "    'svg-500px': 58,\n",
        "    'svg-250px': 59,\n",
        "    'svg': 60,\n",
        "    'h-1': 61,\n",
        "    'h-2': 62,\n",
        "    'h-3': 63,\n",
        "    'h-4': 64,\n",
        "    'h-5': 65,\n",
        "    'h-6': 66,\n",
        "    'h-span': 67,\n",
        "    'h-featurette': 68,\n",
        "    'paragraph': 69,\n",
        "    'paragraph-white': 70,\n",
        "    'paragraph-lead': 71,\n",
        "    'p-btn': 72,\n",
        "    'btn-primary': 73,\n",
        "    'btn-primary-my-1': 74,\n",
        "    'btn-success': 75,\n",
        "    'btn-secondary': 76,\n",
        "    'btn-dark': 77,\n",
        "    'btn-warning': 78,\n",
        "    'btn-danger': 79,\n",
        "    'btn-outline-success': 80,\n",
        "    'btn-outline-danger': 81,\n",
        "    'btn-outline-dark': 82,\n",
        "    'featurette-divider': 83,\n",
        "    'br': 84,\n",
        "    'h5-my-0': 85,\n",
        "    'nav-my-2': 86,\n",
        "    'a-p2-text-dark': 87,\n",
        "    'd-flex': 88,\n",
        "    'text-center': 89,\n",
        "    'card-deck': 90,\n",
        "    'card': 91,\n",
        "    'card-mb-4-shadow-sm': 92,\n",
        "    'card-header': 93,\n",
        "    'card-body': 94,\n",
        "    'card-title': 95,\n",
        "    'list-unstyled': 96,\n",
        "    'li': 97,\n",
        "    'btn-outline-primary': 98,\n",
        "    'album': 99,\n",
        "    'album-py-5': 100,\n",
        "    'album-py-5-bg-light': 101,\n",
        "    'col-md-4': 102,\n",
        "    'svg-bd-placeholder-img-card-img-top': 103,\n",
        "    'p-card-text': 104,\n",
        "    'd-flex-center': 105,\n",
        "    'btn-group': 106,\n",
        "    'btn-outline-secondary': 107,\n",
        "    'small-text-muted': 108,\n",
        "    'nav-item-dropdown': 109,\n",
        "    'nav-link-dropdown-toggle': 110,\n",
        "    'dropdown-menu': 111,\n",
        "    'dropdown-item': 112,\n",
        "    'form-inline': 113,\n",
        "    'form-inline-my-2-my-lg-0': 114,\n",
        "    'jumbotron': 115,\n",
        "    'hr': 116,\n",
        "    'text-muted': 117,\n",
        "    'section-jumbotron-text-center': 118,\n",
        "    'justify-content-center': 119,\n",
        "    'align-items-center': 120,\n",
        "    'collapse-bg-dark': 121,\n",
        "    'col-sm-8-col-md-7-py-4': 122,\n",
        "    'col-sm-4-offset-md-1-py-4': 123,\n",
        "    'h-4-text-white': 124,\n",
        "    'paragraph-lead-text-muted': 125,\n",
        "    'list-unstyled-only': 126,\n",
        "    'a-text-white': 127,\n",
        "    'navbar-dark-bg-dark-shadow': 128,\n",
        "    'd-flex-justify-content-between': 129,\n",
        "    'navbar-toggler-icon-span': 130,\n",
        "    'a-navbar-brand-d-flex-align-items-center': 131,\n",
        "    'jumbotron-center': 132,\n",
        "    'h-jumbotron': 133,\n",
        "    'card-shadow': 134,\n",
        "    'paragraph-card-text': 135,\n",
        "    'card-img-top': 136,\n",
        "    'card-mb-4-shadow': 137,\n",
        "    'btn-outline-secondary-sm': 138,\n",
        "    'btn-primary-my-2': 139,\n",
        "    'btn-dark-my-2': 140,\n",
        "    'btn-secondary-my-2': 141,\n",
        "    'navbar-collapse-dark': 142,\n",
        "    'navbar-collapse-primary': 143,\n",
        "    'navbar-collapse-success': 144,\n",
        "    'navbar-collapse-danger': 145,\n",
        "    'navbar-collapse-warning': 146,\n",
        "    'navbar-collapse-secondary': 147,\n",
        "    'navbar-collapse-light': 148,\n",
        "    'collapse-bg-primary': 149,\n",
        "    'collapse-bg-secondary': 150,\n",
        "    'collapse-bg-success': 151,\n",
        "    'collapse-bg-danger': 152,\n",
        "    'collapse-bg-info': 153,\n",
        "    'paragraph-lead-light': 154,\n",
        "    'navbar-dark-bg-primary-shadow': 155,\n",
        "    'navbar-dark-bg-secondary-shadow': 156,\n",
        "    'navbar-dark-bg-success-shadow': 157,\n",
        "    'navbar-dark-bg-danger-shadow': 158,\n",
        "    'navbar-dark-bg-info-shadow': 159,\n",
        "    'form': 160,\n",
        "    'form-group': 161,\n",
        "    'form-group-mb-2': 162,\n",
        "    'form-group-mx-sm-3-mb-2': 163,\n",
        "    'label': 164,\n",
        "    'label-sr-only': 165,\n",
        "    'label-email-sr-only': 166,\n",
        "    'label-password-sr-only': 167,\n",
        "    'label-email': 168,\n",
        "    'label-password': 169,\n",
        "    'label-phone': 170,\n",
        "    'label-file': 171,\n",
        "    'label-address': 172,\n",
        "    'label-city': 173,\n",
        "    'label-state': 174,\n",
        "    'label-zip': 175,\n",
        "    'label-mr-sm-2': 176,\n",
        "    'label-mr-sm-2-white': 177,\n",
        "    'label-custom-control': 178,\n",
        "    'label-custom-control-white': 179,\n",
        "    'label-my-1-mr-2': 180,\n",
        "    'label-my-1-mr-2-white': 181,\n",
        "    'input-text-form-control': 182,\n",
        "    'input-text-form-control-mb-2': 183,\n",
        "    'input-email-form-control': 184,\n",
        "    'input-password-form-control': 185,\n",
        "    'input-phone-form-control': 186,\n",
        "    'input-file-form-control': 187,\n",
        "    'input-file-form-control-white': 188,\n",
        "    'input-checkbox-form-check': 189,\n",
        "    'input-checkbox': 190,\n",
        "    'input-radio-form-check': 191,\n",
        "    'input-radio-form-check-checked': 192,\n",
        "    'input-radio-form-check-disabled': 193,\n",
        "    'input-checkbox-custom-control': 194,\n",
        "    'select2-form-control': 195,\n",
        "    'select3-form-control': 196,\n",
        "    'select4-form-control': 197,\n",
        "    'select5-form-control': 198,\n",
        "    'textarea-form-control': 199,\n",
        "    'textarea-form-control-6r': 200,\n",
        "    'form-check': 201,\n",
        "    'form-check-disabled': 202,\n",
        "    'form-check-label': 203,\n",
        "    'form-check-label-white': 204,\n",
        "    'small-form-text': 205,\n",
        "    'btn-primary-mb-2': 206,\n",
        "    'form-row': 207,\n",
        "    'form-row-align-items-center': 208,\n",
        "    'form-group-row': 209,\n",
        "    'form-group-col-md-6': 210,\n",
        "    'form-group-col-md-4': 211,\n",
        "    'form-group-col-md-2': 212,\n",
        "    'btn btn-primary': 213,\n",
        "    'col-sm-2-col-form-label': 214,\n",
        "    'col-sm-2-col-form-label-email': 215,\n",
        "    'col-sm-2-col-form-label-email-white': 216,\n",
        "    'col-sm-2-col-form-label-password': 217,\n",
        "    'col-sm-2-col-form-label-password-white': 218,\n",
        "    'col-sm-10': 219,\n",
        "    'col-md-6-mb-3': 220,\n",
        "    'col-md-4-mb-3': 221,\n",
        "    'col-md-3-mb-3': 222,\n",
        "    'legend-radio': 223,\n",
        "    'legend-radio-white': 224,\n",
        "    'fieldset-form-group': 225,\n",
        "    'col-sm-2': 226,\n",
        "    'col-sm-2-white': 227,\n",
        "    'input-group': 228,\n",
        "    'input-group-mb-2': 229,\n",
        "    'input-group-prepend': 230,\n",
        "    'input-group-text': 231,\n",
        "    'span-input-group-text': 232,\n",
        "    'form-check-mb-2': 233,\n",
        "    'custom-control-custom-checkbox-mr-sm-2': 234,\n",
        "    'custom-select-mr-sm-2': 235,\n",
        "    'custom-select-my-1-mr-sm-2': 236,\n",
        "    'custom-control-custom-checkbox-my-1-mr-sm-2': 237,\n",
        "    'custom-file': 238,\n",
        "    'custom-file-input': 239,\n",
        "    'custom-file-label': 240,\n",
        "    'd-flex-flex-column': 241,\n",
        "    'flex-shrink-0': 242,\n",
        "    'section-py-5': 243,\n",
        "    'container-px-5': 244,\n",
        "    'bg-light-rounded-3-py-5-px-4-px-md-5-mb-5': 245,\n",
        "    'bg-dark-rounded-3-py-5-px-4-px-md-5-mb-5': 246,\n",
        "    'bg-info-rounded-3-py-5-px-4-px-md-5-mb-5': 247,\n",
        "    'text-center-mb-5': 248,\n",
        "    'fw-bolder': 249,\n",
        "    'row-gx-5-justify-content-center': 250,\n",
        "    'row-gx-5': 251,\n",
        "    'col-lg-8-col-xl-6': 252,\n",
        "    'form-floating-mb-3': 253,\n",
        "    'form-signin': 254,\n",
        "    'text-center-mb-4': 255,\n",
        "    'img-mb-4': 256,\n",
        "    'h3-mb-3-font-weight-normal': 257,\n",
        "    'h3-mb-3-font-weight-normal-white': 258,\n",
        "    'code': 259,\n",
        "    'a-link': 260,\n",
        "    'checkbox-mb-3': 261,\n",
        "    'btn-btn-lg-btn-primary-btn-block': 262,\n",
        "    'row-justify-content-center': 263,\n",
        "    'col-lg-8-col-xxl-6': 264,\n",
        "    'text-center-my-5': 265,\n",
        "    'h1-fw-bolder-mb-3': 266,\n",
        "    'h1-fw-bolder': 267,\n",
        "    'h2-fw-bolder': 268,\n",
        "    'btn-btn-primary-btn-lg': 269,\n",
        "    'section-py-5-bg-light': 270,\n",
        "    'container-px-5-my-5': 271,\n",
        "    'row-gx-5-align-items-center': 272,\n",
        "    'col-lg-6': 273,\n",
        "    'col-lg-6-col-xl-4': 274,\n",
        "    'position-relative-mb-5': 275,\n",
        "    'position-relative-mb-5-mb-lg-0': 276,\n",
        "    'position-relative': 277,\n",
        "    'img-fluid-rounded-mb-5-mb-lg-0': 278,\n",
        "    'img-fluid-rounded-3-mb-5': 279,\n",
        "    'img-fluid-rounded-3-mb-3': 280,\n",
        "    'col-lg-6-order-first-order-lg-last': 281,\n",
        "    'aside': 282,\n",
        "    'h3-fw-bolder-text-decoration-none-link-dark-stretched-link': 283,\n",
        "    'h2-display-4-fw-bolder-mb-4': 284,\n",
        "    'btn-btn-lg-btn-primary': 285,\n",
        "    'section-bg-light-py-5': 286,\n",
        "    'card-mb-5-mb-xl-0': 287,\n",
        "    'card-body-p-5': 288,\n",
        "    'small-text-uppercase-fw-bold-text-muted': 289,\n",
        "    'small-text-uppercase-fw-bold': 290,\n",
        "    'mb-3': 291,\n",
        "    'display-4-fw-bold': 292,\n",
        "    'list-unstyled-mb-4': 293,\n",
        "    'li-mb-2': 294,\n",
        "    'li-mb-2-text-muted': 295,\n",
        "    'li-text-muted': 296,\n",
        "    'bi-check': 297,\n",
        "    'bi-x': 298,\n",
        "    'bi-star-fill': 299,\n",
        "    'strong': 300,\n",
        "    'd-grid': 301,\n",
        "    'pricing-plan-card-group-d-flex': 302,\n",
        "    'card-set-price-p-1-d-none-d-lg-none-d-lg-block': 303,\n",
        "    'card-header-text-center-pb-4-item': 304,\n",
        "    'h5-pt-3-text-black-card-title': 305,\n",
        "    'span-h1-text-black': 306,\n",
        "    'p-small-text-black': 307,\n",
        "    'h5-pt-3-text-white-card-title': 308,\n",
        "    'span-h1-text-white': 309,\n",
        "    'p-small-text-white': 310,\n",
        "    'card-body-d-flex-flex-column': 311,\n",
        "    'list-unstyled-text-right': 312,\n",
        "    'w-100-d-md-none-mt-4': 313,\n",
        "    'card-p-1-starter': 314,\n",
        "    'list-unstyled-text-center': 315,\n",
        "    'span-d-lg-none': 316,\n",
        "    'fa-check': 317,\n",
        "    'fa-times': 318,\n",
        "    'btn-lg-btn-block-btn-dark-mt-auto': 319,\n",
        "    'btn-lg-btn-block-btn-success-mt-auto': 320,\n",
        "    'card-advanced-p-1': 321,\n",
        "    'card-business-p-1': 322,\n",
        "    'col-md-4-col-sm-6': 323,\n",
        "    'pricingTable': 324,\n",
        "    'svg-0-0-360-220': 325,\n",
        "    'g': 326,\n",
        "    'path-ae003d': 327,\n",
        "    'path-005c99': 328,\n",
        "    'path-db2c29': 329,\n",
        "    'text-78': 330,\n",
        "    'text-29': 331,\n",
        "    'text-15': 332,\n",
        "    'pricing-content': 333,\n",
        "    'h3-title': 334,\n",
        "    'ul-pricing-content': 335,\n",
        "    'b': 336,\n",
        "    'pricingTable-signup': 337,\n",
        "    'pricingTable-blue': 338,\n",
        "    'pricingTable-red': 339,\n",
        "    'col-lg-5-col-md-8-col-sm-8-d-block-m-auto': 340,\n",
        "    'text-primary': 341,\n",
        "    'fa-check-circle': 342,\n",
        "    'pt-2-pb-1': 343,\n",
        "    'h1-pb-3-text-primary-font-weight-bold': 344,\n",
        "    'h1-pb-3-color-primary-text-text-primary-font-weight-bold': 345,\n",
        "    'pb-2': 346,\n",
        "    'row-pb-5': 347,\n",
        "    'col-md-9-col-lg-7': 348,\n",
        "    'btn-lg-btn-block-btn-primary': 349,\n",
        "    'col-lg-1-d-none-d-lg-block': 350,\n",
        "    'vl': 351,\n",
        "    'color-primary-text-text-primary': 352,\n",
        "    'w-50-px-3-py-3-pt-md-4-pb-md-5-mx-auto-text-center': 353,\n",
        "    'h1-display-4-font-weight-bold': 354,\n",
        "    'div': 355,\n",
        "    'paragraph-lead-text-muted-mb-0': 356,\n",
        "    'nav-breadcrumb': 357,\n",
        "    'ol-breadcrumb': 358,\n",
        "    'li-breadcrumb-item': 359,\n",
        "    'li-breadcrumb-item-active': 360,\n",
        "    'card-header-bg-primary-text-white': 361,\n",
        "    'fa-envelope': 362,\n",
        "    'fa-home': 363,\n",
        "    'mx-auto': 364,\n",
        "    'btn-primary-text-right': 365,\n",
        "    'col-12-col-sm-4': 366,\n",
        "    'card-bg-light-mb-3': 367,\n",
        "    'card-header-bg-success-text-white-text-uppercase': 368,\n",
        "    'navbar-navbar-expand-md-navbar-dark-bg-dark': 369,\n",
        "    'collapse-navbar-collapse-justify-content-end': 370,\n",
        "    'navbar-nav-m-auto': 371,\n",
        "    'input-group-input-group-sm': 372,\n",
        "    'input-group-append': 373,\n",
        "    'btn-secondary-btn-number': 374,\n",
        "    'btn-success-btn-sm-ml-3': 375,\n",
        "    'container-padding-top-0': 376,\n",
        "    'h2-text-center': 377,\n",
        "    'col-12-col-md-8-col-lg-6-pb-5': 378,\n",
        "    'card-border-primary-rounded-0': 379,\n",
        "    'card-header-p-0': 380,\n",
        "    'bg-info-text-white-text-center-py-2': 381,\n",
        "    'p-m-0': 382,\n",
        "    'card-body-p-3': 383,\n",
        "    'fa-user-text-info': 384,\n",
        "    'fa-envelope-text-info': 385,\n",
        "    'fa-comment-text-info': 386,\n",
        "    'input-btn-info-btn-block-rounded-0-py-2': 387,\n",
        "    'h3': 388,\n",
        "    'h1-white': 389,\n",
        "    'label-white': 390,\n",
        "    'margin-5p': 391,\n",
        "    'margin-top-3p': 392,\n",
        "    'jumbotron-p-3-p-md-5-text-white-rounded-bg-danger': 393,\n",
        "    'col-md-6': 394,\n",
        "    'col-md-6-px-0': 395,\n",
        "    'h1-display-4-font-italic-custom': 396,\n",
        "    'p-lead-my-3-custom': 397,\n",
        "    'p-lead-mb-0-a-text-white-font-weight-bold': 398,\n",
        "    'row-mb-2': 399,\n",
        "    'card-flex-md-row-mb-4-shadow-sm-h-md-250': 400,\n",
        "    'card-body-d-flex-flex-column-align-items-start': 401,\n",
        "    'strong-d-inline-block-mb-2-text-primary': 402,\n",
        "    'strong-d-inline-block-mb-2-text-success': 403,\n",
        "    'h3-mb-0-a-text-dark-custom': 404,\n",
        "    'mb-1-text-muted-custom': 405,\n",
        "    'p-card-text-mb-auto-custom': 406,\n",
        "    'a-cr-custom': 407,\n",
        "    'svg-card-img-right-flex-auto-d-none-d-lg-block': 408,\n",
        "    'col-md-5-p-lg-5-mx-auto-my-5': 409,\n",
        "    'h1-display-4-font-weight-normal-custom': 410,\n",
        "    'p-lead-font-weight-normal-custom': 411,\n",
        "    'h1-long': 412,\n",
        "    'paragraph-lead-long': 413,\n",
        "    'paragraph-mid': 414,\n",
        "    'any': 415,\n",
        "    '': 416\n",
        "}\n",
        "\n",
        "pickle.dump(data, open('voc.pkl' , 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('/content/voc.pkl','rb') as f:\n",
        "  data = pickle.load(f)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Um499PoLNyq"
      },
      "outputs": [],
      "source": [
        "class ImageEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3)\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3)\n",
        "        self.fc1 = nn.Linear(in_features=128*28*28, out_features=1024)\n",
        "        self.fc2 = nn.Linear(in_features=1024, out_features=1024)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x -> [-1, 3, 256, 256]\n",
        "        \n",
        "        x = F.relu(self.conv1(x))\n",
        "        # x -> [-1, 32, 254, 254]\n",
        "        x = F.relu(self.conv2(x))\n",
        "        # x -> [-1, 32, 252, 252]\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # x -> [-1, 32, 126, 126]\n",
        "        \n",
        "        x = F.relu(self.conv3(x))\n",
        "        # x -> [-1, 64, 124, 124]\n",
        "        x = F.relu(self.conv4(x))\n",
        "        # x -> [-1, 64, 122, 122]\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # x -> [-1, 64, 61, 61]\n",
        "\n",
        "        x = F.relu(self.conv5(x))\n",
        "        # x -> [-1, 128, 59, 59]\n",
        "        x = F.relu(self.conv6(x))\n",
        "        # x -> [-1, 128, 57, 57]\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # x -> [-1, 128, 28, 28]\n",
        "\n",
        "        x = x.view(-1, 128*28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "class ContextEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ContextEncoder, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size=417, hidden_size=128, num_layers=2, batch_first=True)\n",
        "    \n",
        "    def forward(self, x, h=None):\n",
        "        # x -> [-1, seq_size, 19], h -> [num_layer=2,-1, 128]\n",
        "\n",
        "        if not h:\n",
        "            h = torch.zeros((2, x.size(0), 128)).cuda()\n",
        "\n",
        "        x, _ = self.rnn(x, h)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size=1024+128, hidden_size=512, num_layers=2, batch_first=True)\n",
        "        self.l1 = nn.Linear(512, 417)\n",
        "    \n",
        "    def forward(self, image_feature, context_feature, on_cuda = False, h = None):\n",
        "        # image_feature -> [-1, 1024], context_feature -> [-1, seq_size=48, 128], h -> [num_layer=2, -1, 512]\n",
        "        image_feature = image_feature.unsqueeze(1)\n",
        "        # image_feature -> [-1, 1, 1024]\n",
        "        image_feature = image_feature.repeat(1, context_feature.size(1), 1)\n",
        "        # image_feature -> [-1, seq_size, 1024]\n",
        "        x = torch.cat((image_feature, context_feature), 2)\n",
        "        # x -> [-1, seq_size=48, 1024+128]\n",
        "\n",
        "        if not h:\n",
        "            h = torch.zeros((2, x.size(0), 512)).cuda()\n",
        "\n",
        "        x, _ = self.rnn(x, h)\n",
        "        x = self.l1(x)\n",
        "        # x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "class Pix2Code(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Pix2Code, self).__init__()\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.context_encoder = ContextEncoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, image, context):\n",
        "        image_feature = self.image_encoder(image)\n",
        "        context_feature = self.context_encoder(context)\n",
        "        output = self.decoder(image_feature, context_feature)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcDXMzgkLgeb"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "PLACEHOLDER = ' '\n",
        "# CONTEXT_LENGTH = 48\n",
        "image_size = 256\n",
        "\n",
        "\n",
        "class Vocabulary:\n",
        "    \n",
        "    def __init__(self, file_path):\n",
        "        self.load_vocab(file_path)\n",
        "        self.length = len(self.vocab_to_index)\n",
        "    \n",
        "    def load_vocab(self, file_path):\n",
        "        self.vocab_to_index = {}\n",
        "        with open(file_path, 'rb') as vocab_file:\n",
        "            self.vocab_to_index = pickle.load(vocab_file)\n",
        "        self.index_to_vocab = {value:key for key, value in self.vocab_to_index.items()}\n",
        "    \n",
        "    def to_vec(self, word):\n",
        "        vec = np.zeros(self.length)\n",
        "        vec[self.vocab_to_index[word]] = 1\n",
        "        return vec\n",
        "       \n",
        "    def to_vocab(self, index):\n",
        "        return self.index_to_vocab[index]\n",
        "\n",
        "class UIDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, file_path, vocab_file_path):\n",
        "        self.file_path = file_path\n",
        "        self.paths = []\n",
        "        self.get_paths()\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize([image_size, image_size]),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        self.vocab = Vocabulary(vocab_file_path)\n",
        "        \n",
        "    def get_paths(self):\n",
        "        for f in os.listdir(self.file_path):\n",
        "            if f.find('.gui') != -1:\n",
        "                file_name = f[:f.find('.gui')]\n",
        "                if os.path.isfile('{}/{}.png'.format(self.file_path, file_name)):\n",
        "                    self.paths.append(file_name)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return(len(self.paths))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.transform(Image.open('{}/{}.png'.format(self.file_path, self.paths[index])))[:-1]\n",
        "        context, prediction = self.read_gui('{}/{}.gui'.format(self.file_path, self.paths[index]))\n",
        "        return image, context, prediction\n",
        "    \n",
        "    def read_gui(self, file_path):\n",
        "        context = []\n",
        "        prediction = []\n",
        "        \n",
        "        # Tokenize the target code and ads start and end token\n",
        "        token_sequence = [PLACEHOLDER]\n",
        "        token_sequence.append(START_TOKEN)\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                line = line.replace(',', ' ,').replace('\\n', ' \\n')\n",
        "                tokens = line.split(' ')\n",
        "                for token in tokens:\n",
        "                    token_sequence.append(token)\n",
        "        token_sequence.append(END_TOKEN)\n",
        "        \n",
        "        # Generates cotext prediction pair\n",
        "        context = token_sequence[:-1]\n",
        "        prediction = token_sequence[1:]\n",
        "        \n",
        "        # One hot encoding\n",
        "        prediction_vec = []\n",
        "        for word in prediction:\n",
        "            prediction_vec.append(self.vocab.to_vec(word))\n",
        "        context_vec = []\n",
        "        for word in context:\n",
        "            context_vec.append(self.vocab.to_vec(word))\n",
        "        \n",
        "        return torch.tensor(context_vec, dtype=torch.float), torch.tensor(prediction_vec, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oei_mTtkhgGp"
      },
      "outputs": [],
      "source": [
        "loss_history = []\n",
        "acc_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5VOw-1yuNZl"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE3_mP2jFbdJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import transformers\n",
        "import torchvision.models as models\n",
        "\n",
        "dataset = UIDataset('/content/drive/MyDrive/Dataset/WEB_DATASET/WEB_Data_training', '/content/voc-v4.pkl')\n",
        "loss_history = []\n",
        "acc_history = []\n",
        "\n",
        "\n",
        "# Training\n",
        "net = Pix2Code().cuda()\n",
        "\n",
        "# Load the GPT model\n",
        "gpt = transformers.GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "# Extract the state_dict of the GPT model\n",
        "gpt_state_dict = gpt.state_dict()\n",
        "\n",
        "# Extract the state_dict of the context encoder part of the GPT model\n",
        "decoder_state_dict = {k: v for k, v in gpt_state_dict.items() if k in net.decoder.state_dict()}\n",
        "\n",
        "# Load the state_dict of the context encoder part of the GPT model into the corresponding encoder part of the current model\n",
        "net.decoder.load_state_dict(decoder_state_dict, strict=False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = 0.0001)\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    net.zero_grad()\n",
        "    for j, data in enumerate(dataset):\n",
        "        image, context, prediction = data\n",
        "        image = image.unsqueeze(0).cuda()\n",
        "        context = context.unsqueeze(0).cuda()\n",
        "        prediction = prediction.cuda()\n",
        "        output = net(image, context)\n",
        "        output = output.squeeze(0)\n",
        "        prediction = torch.argmax(prediction, 1)\n",
        "        loss = criterion(output, prediction)\n",
        "        loss.backward()\n",
        "        loss_history.append(loss.data)\n",
        "\n",
        "        # calculate accuracy\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        acc = accuracy_score(prediction.cpu().numpy(), predicted.cpu().numpy())\n",
        "        acc_history.append(acc)\n",
        "\n",
        "        if j%10 == 0:\n",
        "            optimizer.step()\n",
        "            print('Epoch: {}, Loss: {},  Accuracy: {}'.format(epoch ,loss.data, acc))\n",
        "            net.zero_grad()\n",
        "\n",
        "\n",
        "torch.save(net.state_dict(), './sketch2code_GPT2_e10.weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jriAPtDDDCi"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/sketch2code_GPT2_e10.weights.weights /content/drive/MyDrive/senior/model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrEnqCb7j5EL"
      },
      "outputs": [],
      "source": [
        "LH = []\n",
        "# VAL_LH = []\n",
        "\n",
        "for i in range(len(loss_history)):\n",
        "  LH.append(loss_history[i].item())\n",
        "\n",
        "# for j in range(len(val_loss_history)):\n",
        "#   VAL_LH.append(val_loss_history[j].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O4Pk8dZj5xy"
      },
      "outputs": [],
      "source": [
        "# Plot loss and accuracy\n",
        "plt.plot(LH)\n",
        "plt.title('Loss')\n",
        "plt.show()\n",
        "plt.plot(acc_history)\n",
        "plt.title('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO8EyTJ15emE"
      },
      "outputs": [],
      "source": [
        "net = Pix2Code()\n",
        "net.load_state_dict(torch.load('/content/Super_GPT2_e10.weights'))\n",
        "net.cuda().eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is54bYCL16az"
      },
      "outputs": [],
      "source": [
        "test_data = UIDataset('/content/test', '/content/voc-v4.pkl')\n",
        "vocab = Vocabulary('/content/voc-v4.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMWu4grB165K"
      },
      "outputs": [],
      "source": [
        "image, *_ = test_data.__getitem__(np.random.randint(len(test_data)))\n",
        "t = transforms.ToPILImage()\n",
        "image = image.unsqueeze(0)\n",
        "t(image.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XIFpyk-18jl"
      },
      "outputs": [],
      "source": [
        "image = image.cuda()\n",
        "ct = []\n",
        "ct.append(vocab.to_vec(' '))\n",
        "ct.append(vocab.to_vec('<START>'))\n",
        "output = ''\n",
        "for i in range(400):\n",
        "    context = torch.tensor(ct).unsqueeze(0).float().cuda()\n",
        "    index = torch.argmax(net(image, context), 2).squeeze()[-1:].squeeze()\n",
        "    v = vocab.to_vocab(int(index))\n",
        "    if v == '<END>':\n",
        "        break\n",
        "    output += v\n",
        "    ct.append(vocab.to_vec(v))\n",
        "\n",
        "with open('/content/output.gui', 'w') as f:\n",
        "    f.write(output)\n",
        "\n",
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
