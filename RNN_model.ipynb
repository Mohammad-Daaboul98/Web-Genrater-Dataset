{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cMOSYXvhKXVN"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/VaibhavYadav/pytorch_pix2code.git\n",
        "# !git clone --single-branch --branch master https://github.com/Mohammad-Daaboul98/Web-Genrater-Dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP9kkS5COkpU",
        "outputId": "ea800a33-6839-4789-9a42-3414b109e7d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rPW47sf-KXVP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_fulUL4-6cv-"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "'\\n': 0,\n",
        "'<START>': 1,\n",
        "'<END>': 2,\n",
        "'}': 3,\n",
        "'{': 4,\n",
        "',': 5,\n",
        "' ': 6,\n",
        "'header': 7,\n",
        "'navbar-dark': 8,\n",
        "'navbar-light': 9,\n",
        "'navbar-primary': 10,\n",
        "'navbar-warning': 11,\n",
        "'navbar-danger': 12,\n",
        "'navbar-secondary': 13,\n",
        "'navbar-success': 14,\n",
        "'navbar-brand': 15,\n",
        "'navbar-toggler': 16,\n",
        "'navbar-toggler-icon': 17,\n",
        "'navbar-collapse': 18,\n",
        "'navbar-nav': 19,\n",
        "'nav-item': 20,\n",
        "'nav-item-active': 21,\n",
        "'nav-item-unactive': 22,\n",
        "'nav-link': 23,\n",
        "'nav-link-undisabled': 24,\n",
        "'nav-link-disabled': 25,\n",
        "'nav-link-active': 26,\n",
        "'form-inline-success': 27,\n",
        "'form-inline-danger': 28,\n",
        "'form-inline-primary': 29,\n",
        "'form-primary': 30,\n",
        "'form-danger': 31,\n",
        "'form-inline-secondary': 32,\n",
        "'form-secondary': 33,\n",
        "'form-inline-warning': 34,\n",
        "'form-inline-dark': 35,\n",
        "'form-dark': 36,\n",
        "'form-inline-light': 37,\n",
        "'from-d-flex': 38,\n",
        "'form-control-me-2': 39,\n",
        "'container-fluid': 40,\n",
        "'container': 41,\n",
        "'container-marketing': 42,\n",
        "'main': 43,\n",
        "'main-container':44,\n",
        "'carousel-slide': 45,\n",
        "'row': 46,\n",
        "'col-lg-4': 47,\n",
        "'col-md-7': 48,\n",
        "'col-md-5': 49,\n",
        "'order-md-2': 50,\n",
        "'svg-140px': 51,\n",
        "'svg-500px': 52,\n",
        "'svg-250px': 53,\n",
        "'svg': 54,\n",
        "'h-1': 55,\n",
        "'h-2': 56,\n",
        "'h-3': 57,\n",
        "'h-4': 58,\n",
        "'h-5': 59,\n",
        "'h-6': 60,\n",
        "'h-span': 61,\n",
        "'h-featurette': 62,\n",
        "'paragraph': 63,\n",
        "'paragraph-lead': 64,\n",
        "'p-btn': 65,\n",
        "'btn-primary': 66,\n",
        "'btn-success': 67,\n",
        "'btn-secondary': 68,\n",
        "'btn-dark': 69,\n",
        "'btn-warning': 70,\n",
        "'btn-danger': 71,\n",
        "'btn-outline-success': 72,\n",
        "'btn-outline-danger': 73,\n",
        "'btn-outline-dark': 74,\n",
        "'featurette-divider': 75,\n",
        "'br': 76,\n",
        "'h5-my-0': 77,\n",
        "'nav-my-2': 78,\n",
        "'a-text-dark': 79,\n",
        "'d-flex': 80,\n",
        "'text-center': 81,\n",
        "'card-deck': 82,\n",
        "'card': 83,\n",
        "'card-mb-4-shadow-sm': 84,\n",
        "'card-header': 85,\n",
        "'card-body': 86,\n",
        "'card-title': 87,\n",
        "'list-unstyled': 88,\n",
        "'li': 89,\n",
        "'btn-outline-primary': 90,\n",
        "'album': 91,\n",
        "'album-py-5-bg-light': 92,\n",
        "'col-md-4': 93,    \n",
        "'svg-bd-placeholder-img-card-img-top': 94,\n",
        "'p-card-text': 95,\n",
        "'d-flex-center': 96,\n",
        "'btn-group': 97,\n",
        "'btn-outline-secondary': 98,\n",
        "'small-text-muted': 99,\n",
        "'nav-item-dropdown': 100,\n",
        "'nav-link-dropdown-toggle': 101,\n",
        "'dropdown-menu': 102,\n",
        "'dropdown-item': 103,\n",
        "'form-inline': 104,\n",
        "'jumbotron': 105,\n",
        "'hr': 106,\n",
        "'text-muted': 107,\n",
        "'section-jumbotron-text-center': 108,\n",
        "'justify-content-center': 109,\n",
        "'align-items-center': 110,\n",
        "'collapse-bg-dark': 111,\n",
        "'col-sm-8-col-md-7-py-4': 112,\n",
        "'col-sm-4-offset-md-1-py-4': 113,\n",
        "'h-4-text-white': 114,\n",
        "'paragraph-lead-text-muted': 115,\n",
        "'list-unstyled-only': 116,\n",
        "'a-text-white': 117,\n",
        "'navbar-dark-bg-dark-shadow': 118,\n",
        "'d-flex-justify-content-between': 119,\n",
        "'navbar-toggler-icon-span': 120,\n",
        "'a-navbar-brand-d-flex-align-items-center': 121,\n",
        "'jumbotron-center': 122,\n",
        "'h-jumbotron': 123,\n",
        "'card-shadow': 124,\n",
        "'paragraph-card-text': 125,\n",
        "'card-img-top': 126,\n",
        "'card-mb-4-shadow': 127,\n",
        "'btn-outline-secondary-sm': 128,\n",
        "'btn-primary-my-2': 129,\n",
        "'btn-secondary-my-2': 130,\n",
        "'navbar-collapse-dark': 131,\n",
        "'navbar-collapse-primary': 132,\n",
        "'navbar-collapse-success': 133,\n",
        "'navbar-collapse-danger': 134,\n",
        "'navbar-collapse-warning': 135,\n",
        "'navbar-collapse-secondary': 136,\n",
        "'navbar-collapse-light': 137,\n",
        "'collapse-bg-primary': 138,\n",
        "'collapse-bg-secondary': 139,\n",
        "'collapse-bg-success': 140,\n",
        "'collapse-bg-danger': 141,\n",
        "'collapse-bg-info': 142,\n",
        "'paragraph-lead-light': 143,\n",
        "'navbar-dark-bg-primary-shadow': 144,\n",
        "'navbar-dark-bg-secondary-shadow': 145,\n",
        "'navbar-dark-bg-success-shadow': 146,\n",
        "'navbar-dark-bg-danger-shadow': 147,\n",
        "'navbar-dark-bg-info-shadow': 148,\n",
        "'': 149\n",
        "}\n",
        "\n",
        "pickle.dump(data, open('voc.pkl' , 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wruqyk-RKXVQ",
        "outputId": "d470fefd-ca56-4247-f9da-9eb56c7d2262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, '<START>': 1, '<END>': 2, '}': 3, '{': 4, ',': 5, ' ': 6, 'header': 7, 'navbar-dark': 8, 'navbar-light': 9, 'navbar-primary': 10, 'navbar-warning': 11, 'navbar-danger': 12, 'navbar-secondary': 13, 'navbar-success': 14, 'navbar-brand': 15, 'navbar-toggler': 16, 'navbar-toggler-icon': 17, 'navbar-collapse': 18, 'navbar-nav': 19, 'nav-item': 20, 'nav-item-active': 21, 'nav-item-unactive': 22, 'nav-link': 23, 'nav-link-undisabled': 24, 'nav-link-disabled': 25, 'nav-link-active': 26, 'form-inline-success': 27, 'form-inline-danger': 28, 'form-inline-primary': 29, 'form-primary': 30, 'form-danger': 31, 'form-inline-secondary': 32, 'form-secondary': 33, 'form-inline-warning': 34, 'form-inline-dark': 35, 'form-dark': 36, 'form-inline-light': 37, 'from-d-flex': 38, 'form-control-me-2': 39, 'container-fluid': 40, 'container': 41, 'container-marketing': 42, 'main': 43, 'main-container': 44, 'carousel-slide': 45, 'row': 46, 'col-lg-4': 47, 'col-md-7': 48, 'col-md-5': 49, 'order-md-2': 50, 'svg-140px': 51, 'svg-500px': 52, 'svg-250px': 53, 'svg': 54, 'h-1': 55, 'h-2': 56, 'h-3': 57, 'h-4': 58, 'h-5': 59, 'h-6': 60, 'h-span': 61, 'h-featurette': 62, 'paragraph': 63, 'paragraph-lead': 64, 'p-btn': 65, 'btn-primary': 66, 'btn-success': 67, 'btn-secondary': 68, 'btn-dark': 69, 'btn-warning': 70, 'btn-danger': 71, 'btn-outline-success': 72, 'btn-outline-danger': 73, 'btn-outline-dark': 74, 'featurette-divider': 75, 'br': 76, 'h5-my-0': 77, 'nav-my-2': 78, 'a-text-dark': 79, 'd-flex': 80, 'text-center': 81, 'card-deck': 82, 'card': 83, 'card-mb-4-shadow-sm': 84, 'card-header': 85, 'card-body': 86, 'card-title': 87, 'list-unstyled': 88, 'li': 89, 'btn-outline-primary': 90, 'album': 91, 'album-py-5-bg-light': 92, 'col-md-4': 93, 'svg-bd-placeholder-img-card-img-top': 94, 'p-card-text': 95, 'd-flex-center': 96, 'btn-group': 97, 'btn-outline-secondary': 98, 'small-text-muted': 99, 'nav-item-dropdown': 100, 'nav-link-dropdown-toggle': 101, 'dropdown-menu': 102, 'dropdown-item': 103, 'form-inline': 104, 'jumbotron': 105, 'hr': 106, 'text-muted': 107, 'section-jumbotron-text-center': 108, 'justify-content-center': 109, 'align-items-center': 110, 'collapse-bg-dark': 111, 'col-sm-8-col-md-7-py-4': 112, 'col-sm-4-offset-md-1-py-4': 113, 'h-4-text-white': 114, 'paragraph-lead-text-muted': 115, 'list-unstyled-only': 116, 'a-text-white': 117, 'navbar-dark-bg-dark-shadow': 118, 'd-flex-justify-content-between': 119, 'navbar-toggler-icon-span': 120, 'a-navbar-brand-d-flex-align-items-center': 121, 'jumbotron-center': 122, 'h-jumbotron': 123, 'card-shadow': 124, 'paragraph-card-text': 125, 'card-img-top': 126, 'card-mb-4-shadow': 127, 'btn-outline-secondary-sm': 128, 'btn-primary-my-2': 129, 'btn-secondary-my-2': 130, 'navbar-collapse-dark': 131, 'navbar-collapse-primary': 132, 'navbar-collapse-success': 133, 'navbar-collapse-danger': 134, 'navbar-collapse-warning': 135, 'navbar-collapse-secondary': 136, 'navbar-collapse-light': 137, 'collapse-bg-primary': 138, 'collapse-bg-secondary': 139, 'collapse-bg-success': 140, 'collapse-bg-danger': 141, 'collapse-bg-info': 142, 'paragraph-lead-light': 143, 'navbar-dark-bg-primary-shadow': 144, 'navbar-dark-bg-secondary-shadow': 145, 'navbar-dark-bg-success-shadow': 146, 'navbar-dark-bg-danger-shadow': 147, 'navbar-dark-bg-info-shadow': 148, '': 149}\n"
          ]
        }
      ],
      "source": [
        "with open('/content/voc.pkl','rb') as f:\n",
        "  data = pickle.load(f)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ThXxZ55oKXVQ"
      },
      "outputs": [],
      "source": [
        "class ImageEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3)\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3)\n",
        "        self.fc1 = nn.Linear(in_features=128*28*28, out_features=1024)\n",
        "        self.fc2 = nn.Linear(in_features=1024, out_features=1024)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x -> [-1, 3, 256, 256]\n",
        "        \n",
        "        x = F.relu(self.conv1(x))\n",
        "        # x -> [-1, 32, 254, 254]\n",
        "        x = F.relu(self.conv2(x))\n",
        "        # x -> [-1, 32, 252, 252]\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # x -> [-1, 32, 126, 126]\n",
        "        \n",
        "        x = F.relu(self.conv3(x))\n",
        "        # x -> [-1, 64, 124, 124]\n",
        "        x = F.relu(self.conv4(x))\n",
        "        # x -> [-1, 64, 122, 122]\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # x -> [-1, 64, 61, 61]\n",
        "\n",
        "        x = F.relu(self.conv5(x))\n",
        "        # x -> [-1, 128, 59, 59]\n",
        "        x = F.relu(self.conv6(x))\n",
        "        # x -> [-1, 128, 57, 57]\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # x -> [-1, 128, 28, 28]\n",
        "\n",
        "        x = x.view(-1, 128*28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "class ContextEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ContextEncoder, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size=150, hidden_size=128, num_layers=2, batch_first=True)\n",
        "    \n",
        "    def forward(self, x, h=None):\n",
        "        # x -> [-1, seq_size, 19], h -> [num_layer=2,-1, 128]\n",
        "\n",
        "        if not h:\n",
        "            h = torch.zeros((2, x.size(0), 128)).cuda()\n",
        "\n",
        "        x, _ = self.rnn(x, h)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size=1024+128, hidden_size=512, num_layers=2, batch_first=True)\n",
        "        self.l1 = nn.Linear(512, 150)\n",
        "    \n",
        "    def forward(self, image_feature, context_feature, on_cuda = False, h = None):\n",
        "        # image_feature -> [-1, 1024], context_feature -> [-1, seq_size=48, 128], h -> [num_layer=2, -1, 512]\n",
        "        image_feature = image_feature.unsqueeze(1)\n",
        "        # image_feature -> [-1, 1, 1024]\n",
        "        image_feature = image_feature.repeat(1, context_feature.size(1), 1)\n",
        "        # image_feature -> [-1, seq_size, 1024]\n",
        "        x = torch.cat((image_feature, context_feature), 2)\n",
        "        # x -> [-1, seq_size=48, 1024+128]\n",
        "\n",
        "        if not h:\n",
        "            h = torch.zeros((2, x.size(0), 512)).cuda()\n",
        "\n",
        "        x, _ = self.rnn(x, h)\n",
        "        x = self.l1(x)\n",
        "        # x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "class Pix2Code(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Pix2Code, self).__init__()\n",
        "        self.image_encoder = ImageEncoder()\n",
        "        self.context_encoder = ContextEncoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, image, context):\n",
        "        image_feature = self.image_encoder(image)\n",
        "        context_feature = self.context_encoder(context)\n",
        "        output = self.decoder(image_feature, context_feature)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cOQm1ZhEKXVR"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "PLACEHOLDER = ' '\n",
        "# CONTEXT_LENGTH = 48\n",
        "image_size = 256\n",
        "\n",
        "\n",
        "class Vocabulary:\n",
        "    \n",
        "    def __init__(self, file_path):\n",
        "        self.load_vocab(file_path)\n",
        "        self.length = len(self.vocab_to_index)\n",
        "    \n",
        "    def load_vocab(self, file_path):\n",
        "        self.vocab_to_index = {}\n",
        "        with open(file_path, 'rb') as vocab_file:\n",
        "            self.vocab_to_index = pickle.load(vocab_file)\n",
        "        self.index_to_vocab = {value:key for key, value in self.vocab_to_index.items()}\n",
        "    \n",
        "    def to_vec(self, word):\n",
        "        vec = np.zeros(self.length)\n",
        "        vec[self.vocab_to_index[word]] = 1\n",
        "        return vec\n",
        "       \n",
        "    def to_vocab(self, index):\n",
        "        return self.index_to_vocab[index]\n",
        "\n",
        "class UIDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, file_path, vocab_file_path):\n",
        "        self.file_path = file_path\n",
        "        self.paths = []\n",
        "        self.get_paths()\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize([image_size, image_size]),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        self.vocab = Vocabulary(vocab_file_path)\n",
        "        \n",
        "    def get_paths(self):\n",
        "        for f in os.listdir(self.file_path):\n",
        "            if f.find('.gui') != -1:\n",
        "                file_name = f[:f.find('.gui')]\n",
        "                if os.path.isfile('{}/{}.png'.format(self.file_path, file_name)):\n",
        "                    self.paths.append(file_name)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return(len(self.paths))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.transform(Image.open('{}/{}.png'.format(self.file_path, self.paths[index])))[:-1]\n",
        "        context, prediction = self.read_gui('{}/{}.gui'.format(self.file_path, self.paths[index]))\n",
        "        return image, context, prediction\n",
        "    \n",
        "    def read_gui(self, file_path):\n",
        "        context = []\n",
        "        prediction = []\n",
        "        \n",
        "        # Tokenize the target code and ads start and end token\n",
        "        token_sequence = [PLACEHOLDER]\n",
        "        token_sequence.append(START_TOKEN)\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                line = line.replace(',', ' ,').replace('\\n', ' \\n')\n",
        "                tokens = line.split(' ')\n",
        "                for token in tokens:\n",
        "                    token_sequence.append(token)\n",
        "        token_sequence.append(END_TOKEN)\n",
        "        \n",
        "        # Generates cotext prediction pair\n",
        "        context = token_sequence[:-1]\n",
        "        prediction = token_sequence[1:]\n",
        "        \n",
        "        # suffix = [PLACEHOLDER] * CONTEXT_LENGTH\n",
        "        # a = np.concatenate([suffix, token_sequence])\n",
        "        # for j in range(len(token_sequence)):\n",
        "        #     # context.append(a[j:j + CONTEXT_LENGTH])\n",
        "        #     context.append(a[j])\n",
        "        #     prediction.append(a[j + CONTEXT_LENGTH])\n",
        "        \n",
        "        # One hot encoding\n",
        "        prediction_vec = []\n",
        "        for word in prediction:\n",
        "            prediction_vec.append(self.vocab.to_vec(word))\n",
        "        context_vec = []\n",
        "        for word in context:\n",
        "            context_vec.append(self.vocab.to_vec(word))\n",
        "        \n",
        "        return torch.tensor(context_vec, dtype=torch.float), torch.tensor(prediction_vec, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iV_bKh6tKXVS"
      },
      "outputs": [],
      "source": [
        "dataset = UIDataset('/content/drive/MyDrive/Senior/dataset/train', '/content/voc.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0zq3nB_KXVS"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2WrvOS6IKXVT"
      },
      "outputs": [],
      "source": [
        "net = Pix2Code().cuda()\n",
        "# net.load_state_dict(torch.load('/content/drive/MyDrive/Senior/pix2code.weights'))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqFyMpVcKXVU",
        "outputId": "eaf61dca-5ed3-4905-d67e-a18f89062f93",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-66a3df498791>:93: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  return torch.tensor(context_vec, dtype=torch.float), torch.tensor(prediction_vec, dtype=torch.float)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 5.009607315063477, Epoch: 0\n",
            "Loss: 4.900683879852295, Epoch: 0\n",
            "Loss: 4.776477336883545, Epoch: 0\n",
            "Loss: 4.583842754364014, Epoch: 0\n",
            "Loss: 4.3156538009643555, Epoch: 0\n",
            "Loss: 3.9292891025543213, Epoch: 0\n",
            "Loss: 3.5900518894195557, Epoch: 0\n",
            "Loss: 3.3005616664886475, Epoch: 0\n",
            "Loss: 3.237410068511963, Epoch: 0\n",
            "Loss: 3.1536269187927246, Epoch: 0\n",
            "Loss: 3.1202759742736816, Epoch: 0\n",
            "Loss: 2.9757041931152344, Epoch: 0\n",
            "Loss: 2.8676867485046387, Epoch: 0\n",
            "Loss: 2.8345115184783936, Epoch: 0\n",
            "Loss: 2.7255942821502686, Epoch: 0\n",
            "Loss: 2.7266812324523926, Epoch: 0\n",
            "Loss: 2.7463724613189697, Epoch: 0\n",
            "Loss: 2.7744944095611572, Epoch: 0\n",
            "Loss: 2.705498218536377, Epoch: 0\n",
            "Loss: 2.654867172241211, Epoch: 0\n",
            "Loss: 2.7401812076568604, Epoch: 0\n",
            "Loss: 2.6131672859191895, Epoch: 0\n",
            "Loss: 2.634950637817383, Epoch: 0\n",
            "Loss: 2.593686580657959, Epoch: 0\n",
            "Loss: 2.636951446533203, Epoch: 0\n",
            "Loss: 2.667710542678833, Epoch: 0\n",
            "Loss: 2.613354444503784, Epoch: 0\n",
            "Loss: 2.5534214973449707, Epoch: 0\n",
            "Loss: 2.570624589920044, Epoch: 0\n",
            "Loss: 2.5691983699798584, Epoch: 0\n",
            "Loss: 2.548391103744507, Epoch: 0\n",
            "Loss: 2.5381805896759033, Epoch: 0\n",
            "Loss: 2.5589656829833984, Epoch: 0\n",
            "Loss: 2.604876756668091, Epoch: 0\n",
            "Loss: 2.51658296585083, Epoch: 0\n",
            "Loss: 2.514385938644409, Epoch: 0\n",
            "Loss: 2.542530059814453, Epoch: 0\n",
            "Loss: 2.508336305618286, Epoch: 0\n",
            "Loss: 2.4948344230651855, Epoch: 0\n",
            "Loss: 2.5551624298095703, Epoch: 0\n",
            "Loss: 2.5336410999298096, Epoch: 0\n",
            "Loss: 2.4640417098999023, Epoch: 0\n",
            "Loss: 2.5352115631103516, Epoch: 0\n",
            "Loss: 2.4377248287200928, Epoch: 0\n",
            "Loss: 2.480670213699341, Epoch: 0\n",
            "Loss: 2.584120988845825, Epoch: 0\n",
            "Loss: 2.523622512817383, Epoch: 0\n",
            "Loss: 2.6234400272369385, Epoch: 0\n",
            "Loss: 2.4908719062805176, Epoch: 0\n",
            "Loss: 2.4523072242736816, Epoch: 0\n",
            "Loss: 2.7310848236083984, Epoch: 0\n",
            "Loss: 2.4879724979400635, Epoch: 0\n",
            "Loss: 2.558624267578125, Epoch: 0\n",
            "Loss: 2.4360666275024414, Epoch: 0\n",
            "Loss: 2.487297296524048, Epoch: 0\n",
            "Loss: 2.4056222438812256, Epoch: 0\n",
            "Loss: 2.4792068004608154, Epoch: 0\n",
            "Loss: 2.563573122024536, Epoch: 0\n",
            "Loss: 2.653216600418091, Epoch: 0\n",
            "Loss: 2.5613765716552734, Epoch: 0\n",
            "Loss: 2.5064353942871094, Epoch: 0\n",
            "Loss: 2.525834798812866, Epoch: 0\n",
            "Loss: 2.519838571548462, Epoch: 0\n",
            "Loss: 2.5122644901275635, Epoch: 0\n",
            "Loss: 2.518527030944824, Epoch: 0\n",
            "Loss: 2.550610303878784, Epoch: 0\n",
            "Loss: 2.495920419692993, Epoch: 0\n",
            "Loss: 2.4895541667938232, Epoch: 0\n",
            "Loss: 2.511868476867676, Epoch: 0\n",
            "Loss: 2.5443146228790283, Epoch: 0\n",
            "Loss: 2.515568971633911, Epoch: 0\n",
            "Loss: 2.4590747356414795, Epoch: 0\n",
            "Loss: 2.4782497882843018, Epoch: 0\n",
            "Loss: 2.5772929191589355, Epoch: 0\n",
            "Loss: 2.525686502456665, Epoch: 0\n",
            "Loss: 2.4251606464385986, Epoch: 0\n",
            "Loss: 2.496504306793213, Epoch: 0\n",
            "Loss: 2.5479650497436523, Epoch: 0\n",
            "Loss: 2.5366051197052, Epoch: 0\n",
            "Loss: 2.5415215492248535, Epoch: 0\n",
            "Loss: 2.5269668102264404, Epoch: 0\n",
            "Loss: 2.4236762523651123, Epoch: 0\n",
            "Loss: 2.5276713371276855, Epoch: 0\n",
            "Loss: 2.496147394180298, Epoch: 0\n",
            "Loss: 2.4828224182128906, Epoch: 0\n",
            "Loss: 2.6080567836761475, Epoch: 0\n",
            "Loss: 2.5322911739349365, Epoch: 0\n",
            "Loss: 2.429833173751831, Epoch: 0\n",
            "Loss: 2.4928367137908936, Epoch: 0\n",
            "Loss: 2.4485652446746826, Epoch: 0\n",
            "Loss: 2.520434856414795, Epoch: 0\n",
            "Loss: 2.455493688583374, Epoch: 0\n",
            "Loss: 2.506784439086914, Epoch: 0\n",
            "Loss: 2.6040050983428955, Epoch: 0\n",
            "Loss: 2.54777193069458, Epoch: 0\n",
            "Loss: 2.469442129135132, Epoch: 0\n",
            "Loss: 2.478416919708252, Epoch: 0\n",
            "Loss: 2.542797565460205, Epoch: 0\n",
            "Loss: 2.4814693927764893, Epoch: 0\n",
            "Loss: 2.3705320358276367, Epoch: 0\n",
            "Loss: 2.559981107711792, Epoch: 0\n",
            "Loss: 2.3186442852020264, Epoch: 0\n",
            "Loss: 2.490983486175537, Epoch: 0\n",
            "Loss: 2.539226531982422, Epoch: 0\n",
            "Loss: 2.334927558898926, Epoch: 0\n",
            "Loss: 2.4505083560943604, Epoch: 0\n",
            "Loss: 2.5097262859344482, Epoch: 0\n",
            "Loss: 2.3978593349456787, Epoch: 0\n",
            "Loss: 2.3895106315612793, Epoch: 0\n",
            "Loss: 2.49413800239563, Epoch: 0\n",
            "Loss: 2.4069042205810547, Epoch: 0\n",
            "Loss: 2.4593632221221924, Epoch: 0\n",
            "Loss: 2.448537826538086, Epoch: 0\n",
            "Loss: 2.330329179763794, Epoch: 0\n",
            "Loss: 2.3832170963287354, Epoch: 0\n",
            "Loss: 2.4595961570739746, Epoch: 0\n",
            "Loss: 2.484077215194702, Epoch: 0\n",
            "Loss: 2.3786346912384033, Epoch: 0\n",
            "Loss: 2.4827518463134766, Epoch: 0\n",
            "Loss: 2.545219898223877, Epoch: 0\n",
            "Loss: 2.491302967071533, Epoch: 0\n",
            "Loss: 2.5523521900177, Epoch: 0\n",
            "Loss: 2.3774209022521973, Epoch: 0\n",
            "Loss: 2.4139187335968018, Epoch: 0\n",
            "Loss: 2.507922649383545, Epoch: 0\n",
            "Loss: 2.4496445655822754, Epoch: 0\n",
            "Loss: 2.37843656539917, Epoch: 0\n",
            "Loss: 2.3724942207336426, Epoch: 0\n",
            "Loss: 2.3244423866271973, Epoch: 0\n",
            "Loss: 2.5110907554626465, Epoch: 0\n",
            "Loss: 2.4166383743286133, Epoch: 0\n",
            "Loss: 2.375608444213867, Epoch: 0\n",
            "Loss: 2.5046398639678955, Epoch: 0\n",
            "Loss: 2.3686861991882324, Epoch: 0\n",
            "Loss: 2.41843318939209, Epoch: 0\n",
            "Loss: 2.3579301834106445, Epoch: 0\n",
            "Loss: 2.6724483966827393, Epoch: 0\n",
            "Loss: 2.4221150875091553, Epoch: 0\n",
            "Loss: 2.4748311042785645, Epoch: 0\n",
            "Loss: 2.4032182693481445, Epoch: 0\n",
            "Loss: 2.4856996536254883, Epoch: 0\n",
            "Loss: 2.412670135498047, Epoch: 0\n",
            "Loss: 2.5338826179504395, Epoch: 0\n",
            "Loss: 2.3544905185699463, Epoch: 0\n",
            "Loss: 2.446413993835449, Epoch: 0\n",
            "Loss: 2.465681314468384, Epoch: 0\n",
            "Loss: 2.6224052906036377, Epoch: 0\n",
            "Loss: 2.4389185905456543, Epoch: 0\n",
            "Loss: 2.464409112930298, Epoch: 0\n",
            "Loss: 2.42849063873291, Epoch: 0\n",
            "Loss: 2.439469337463379, Epoch: 0\n",
            "Loss: 2.4549429416656494, Epoch: 0\n",
            "Loss: 2.461625337600708, Epoch: 0\n",
            "Loss: 2.349689483642578, Epoch: 0\n",
            "Loss: 2.4826457500457764, Epoch: 0\n",
            "Loss: 2.3968348503112793, Epoch: 0\n",
            "Loss: 2.374551296234131, Epoch: 0\n",
            "Loss: 2.4397668838500977, Epoch: 0\n",
            "Loss: 2.4667930603027344, Epoch: 0\n",
            "Loss: 2.427612781524658, Epoch: 0\n",
            "Loss: 2.473327398300171, Epoch: 0\n",
            "Loss: 2.4476375579833984, Epoch: 0\n",
            "Loss: 2.4007513523101807, Epoch: 0\n",
            "Loss: 2.4011833667755127, Epoch: 0\n",
            "Loss: 2.3860316276550293, Epoch: 0\n",
            "Loss: 2.4582579135894775, Epoch: 0\n",
            "Loss: 2.4760751724243164, Epoch: 0\n",
            "Loss: 2.3842718601226807, Epoch: 0\n",
            "Loss: 2.374262571334839, Epoch: 0\n",
            "Loss: 2.469226837158203, Epoch: 0\n",
            "Loss: 2.3918120861053467, Epoch: 0\n",
            "Loss: 2.355058431625366, Epoch: 0\n",
            "Loss: 2.51863694190979, Epoch: 0\n",
            "Loss: 2.4942338466644287, Epoch: 0\n",
            "Loss: 2.398305892944336, Epoch: 0\n",
            "Loss: 2.3824620246887207, Epoch: 0\n",
            "Loss: 2.3498494625091553, Epoch: 0\n",
            "Loss: 2.4289193153381348, Epoch: 0\n",
            "Loss: 2.33939528465271, Epoch: 0\n",
            "Loss: 2.3381125926971436, Epoch: 0\n",
            "Loss: 2.3425228595733643, Epoch: 0\n",
            "Loss: 2.3104541301727295, Epoch: 0\n",
            "Loss: 2.293433666229248, Epoch: 0\n",
            "Loss: 2.3427395820617676, Epoch: 0\n",
            "Loss: 2.4823880195617676, Epoch: 0\n",
            "Loss: 2.346472978591919, Epoch: 0\n",
            "Loss: 2.2676889896392822, Epoch: 0\n",
            "Loss: 2.2300617694854736, Epoch: 0\n",
            "Loss: 2.197476387023926, Epoch: 0\n",
            "Loss: 2.3398594856262207, Epoch: 0\n",
            "Loss: 2.2297465801239014, Epoch: 0\n",
            "Loss: 2.172194242477417, Epoch: 0\n",
            "Loss: 2.1782851219177246, Epoch: 0\n",
            "Loss: 2.210038661956787, Epoch: 0\n",
            "Loss: 2.113462209701538, Epoch: 0\n",
            "Loss: 2.2637975215911865, Epoch: 0\n",
            "Loss: 2.1852288246154785, Epoch: 0\n",
            "Loss: 2.1460511684417725, Epoch: 0\n",
            "Loss: 2.1118228435516357, Epoch: 0\n",
            "Loss: 2.16438364982605, Epoch: 0\n",
            "Loss: 2.1499714851379395, Epoch: 0\n",
            "Loss: 2.181370496749878, Epoch: 0\n",
            "Loss: 2.2398157119750977, Epoch: 0\n",
            "Loss: 2.0047171115875244, Epoch: 0\n",
            "Loss: 1.9932477474212646, Epoch: 0\n",
            "Loss: 2.0036370754241943, Epoch: 0\n",
            "Loss: 1.9878853559494019, Epoch: 0\n",
            "Loss: 1.9837493896484375, Epoch: 0\n",
            "Loss: 2.071012258529663, Epoch: 0\n",
            "Loss: 1.9821921586990356, Epoch: 0\n",
            "Loss: 1.9726579189300537, Epoch: 0\n",
            "Loss: 1.9417046308517456, Epoch: 0\n",
            "Loss: 1.879348874092102, Epoch: 0\n",
            "Loss: 2.001922369003296, Epoch: 0\n",
            "Loss: 1.940461277961731, Epoch: 0\n",
            "Loss: 1.8021535873413086, Epoch: 0\n",
            "Loss: 1.908352255821228, Epoch: 0\n",
            "Loss: 1.7996025085449219, Epoch: 0\n",
            "Loss: 1.87691330909729, Epoch: 0\n",
            "Loss: 1.8049005270004272, Epoch: 0\n",
            "Loss: 1.8122334480285645, Epoch: 0\n",
            "Loss: 1.8213472366333008, Epoch: 0\n",
            "Loss: 1.8126823902130127, Epoch: 0\n",
            "Loss: 1.864013910293579, Epoch: 0\n",
            "Loss: 1.6551462411880493, Epoch: 0\n",
            "Loss: 1.5722744464874268, Epoch: 0\n",
            "Loss: 1.7004179954528809, Epoch: 0\n",
            "Loss: 1.7337710857391357, Epoch: 0\n",
            "Loss: 1.5497066974639893, Epoch: 0\n",
            "Loss: 1.6313612461090088, Epoch: 0\n",
            "Loss: 1.6955550909042358, Epoch: 1\n",
            "Loss: 1.7258762121200562, Epoch: 1\n",
            "Loss: 1.7201616764068604, Epoch: 1\n",
            "Loss: 1.6057939529418945, Epoch: 1\n",
            "Loss: 1.6684941053390503, Epoch: 1\n",
            "Loss: 1.6808615922927856, Epoch: 1\n",
            "Loss: 1.60079824924469, Epoch: 1\n",
            "Loss: 1.5493040084838867, Epoch: 1\n",
            "Loss: 1.5401225090026855, Epoch: 1\n",
            "Loss: 1.5828815698623657, Epoch: 1\n",
            "Loss: 1.6437432765960693, Epoch: 1\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    net.zero_grad()\n",
        "    for j, data in enumerate(dataset):\n",
        "        image, context, prediction = data\n",
        "        image = image.unsqueeze(0).cuda()\n",
        "        context = context.unsqueeze(0).cuda()\n",
        "        prediction = prediction.cuda()\n",
        "        output = net(image, context)\n",
        "        output = output.squeeze(0)\n",
        "        prediction = torch.argmax(prediction, 1)\n",
        "        loss = criterion(output, prediction)\n",
        "        loss.backward()\n",
        "        if j%10 == 0:\n",
        "            optimizer.step()\n",
        "            print('Loss: {}, Epoch: {}'.format(loss.data, epoch))\n",
        "            net.zero_grad()\n",
        "\n",
        "torch.save(net.state_dict(), './pix2code_10E.weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q9y3-cCyN03O"
      },
      "outputs": [],
      "source": [
        "!cp /content/pix2code_10E.weights /content/drive/MyDrive/Senior/pytorch_pix2code_weights/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWddmVVrKXVU"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNekfuzjKXVV",
        "outputId": "12fdc1ad-2395-40e9-8dc8-bcacd0774417"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pix2Code(\n",
              "  (image_encoder): ImageEncoder(\n",
              "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (fc1): Linear(in_features=100352, out_features=1024, bias=True)\n",
              "    (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (context_encoder): ContextEncoder(\n",
              "    (rnn): RNN(150, 128, num_layers=2, batch_first=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (rnn): RNN(1152, 512, num_layers=2, batch_first=True)\n",
              "    (l1): Linear(in_features=512, out_features=150, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = Pix2Code()\n",
        "net.load_state_dict(torch.load('/content/pix2code_10E.weights'))\n",
        "net.cuda().eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "P6UBOtX_e1xK"
      },
      "outputs": [],
      "source": [
        "# !mkdir /content/test\n",
        "# !cp /content/drive/MyDrive/Senior/dataset/train/0.png /content/test\n",
        "# !touch /content/test/0.gui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FWVBBGf2KXVV"
      },
      "outputs": [],
      "source": [
        "test_data = UIDataset('/content/drive/MyDrive/Senior/dataset/test', '/content/voc.pkl')\n",
        "vocab = Vocabulary('/content/voc.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "aYheXIpuKXVV",
        "outputId": "1d9bcd2d-6810-42a7-eabc-76cbc59e5634"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FA8B1061B20>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image, *_ = test_data.__getitem__(np.random.randint(len(test_data)))\n",
        "t = transforms.ToPILImage()\n",
        "image = image.unsqueeze(0)\n",
        "t(image.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3syNZacKXVV",
        "outputId": "10cbe42b-d330-47cb-c4c6-3fb8730f6389",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "header{\n",
            "container{\n",
            "container{\n",
            "col-md-4{\n",
            "col-md-4{\n",
            "h-2\n",
            "paragraph\n",
            "li\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "image = image.cuda()\n",
        "ct = []\n",
        "ct.append(vocab.to_vec(' '))\n",
        "ct.append(vocab.to_vec('<START>'))\n",
        "output = ''\n",
        "for i in range(200):\n",
        "    context = torch.tensor(ct).unsqueeze(0).float().cuda()\n",
        "    index = torch.argmax(net(image, context), 2).squeeze()[-1:].squeeze()\n",
        "    v = vocab.to_vocab(int(index))\n",
        "    if v == '<END>':\n",
        "        break\n",
        "    output += v\n",
        "    ct.append(vocab.to_vec(v))\n",
        "\n",
        "with open('./output.gui', 'w') as f:\n",
        "    f.write(output)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxKU1JXTKXVW"
      },
      "source": [
        "Now from the compiler directory in your terminal run\n",
        "`python web-compiler.py output.gui`.\n",
        "This will generate a `output.html` file that you can open in your browser."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit ('pytorch': conda)",
      "language": "python",
      "name": "python38264bitpytorchcondaf04cb2303bb94659b54446e023c3cb62"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
